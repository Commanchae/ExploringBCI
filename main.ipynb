{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pylsl import StreamInlet, resolve_stream\n",
    "from brainflow.data_filter import DataFilter, WindowOperations, WaveletTypes, AggOperations, WindowOperations, WaveletDenoisingTypes, WaveletExtensionTypes, NoiseEstimationLevelTypes, ThresholdTypes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame.mixer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_data(duration):\n",
    "    '''\n",
    "    Input: duration (in seconds) of the EEG recording.\n",
    "\n",
    "    Output: A numpy array of size or shape (channel, timesteps). Where channel is 4 for Muse2\n",
    "        and timestep varies for each recording.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # PyLSL to collect the EEG data streamed from BlueMuse.\n",
    "    # Code adapted from: https://github.com/chkothe/pylsl/blob/master/examples/ReceiveData.py\n",
    "    streams = resolve_stream('type', 'EEG')\n",
    "    inlet = StreamInlet(streams[0])\n",
    "    data = []\n",
    "\n",
    "    # This captures data for a specified duration (in seconds).\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration:    \n",
    "        sample, timestamp = inlet.pull_sample()    \n",
    "        data.append(sample)\n",
    "    data_array = np.array(data).T\n",
    "    data_array = np.ascontiguousarray(data_array)\n",
    "    return data_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_trim(data, target_length):\n",
    "    '''\n",
    "    Input: data (coming from EEG recording) with shape (channels, timesteps).\n",
    "            target_length to either pad or trim the timesteps to the desired level.\n",
    "        \n",
    "    Output: A modified version of data which the timesteps trimmed.\n",
    "\n",
    "    For example, recording with Muse2 can yield 250 - 265 timesteps due to certain inconsistencies.\n",
    "    We can use this function to always trim/pad the data recorded and limit it to 256 timesteps (From (4, 260) to (4, 256))\n",
    "\n",
    "    '''\n",
    "    if data.shape[1] < target_length:\n",
    "        pad_width = target_length - data.shape[1]\n",
    "        data = np.pad(data, ((0, 0), (0, pad_width)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        data = data[:, :target_length]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muse2 Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Board Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section has been removed as Brainflow had connectivity issues. Streaming is now done through BlueMuse application and PyLSL library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is so we don't overwrite the entire data when we re-run the collection.\n",
    "session_features = None\n",
    "session_labels = None\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_sfx = pygame.mixer.Sound('Sound Effects/Enter.mp3')\n",
    "sampling_freq = 256 # Muse2's sampling frequency. (How many timesteps per second)\n",
    "\n",
    "duration = 2 # How long should each sample be? (in seconds)\n",
    "rest_time = 2 # How many seconds in between each recording?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1\n",
    "midi_note = 1 # Initially, let's just try 1 2 3 for do re mi (think of the word along with the sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Be sure to only blink during the rest times allocated.\")\n",
    "\n",
    "session_start = datetime.now().strftime('%d-%m-%Y %H_%M')\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(\"Iteration \", i + 1, \"/\", iterations)\n",
    "    print(\"Think of the note: \", midi_note, \"in \", rest_time, \" second(s).\")\n",
    "    time.sleep(rest_time)\n",
    "\n",
    "    ## Streaming ##\n",
    "    #data = stream_data(duration=duration)\n",
    "    data = data_array.T.copy()\n",
    "    if done_sfx:\n",
    "        done_sfx.play()\n",
    "\n",
    "    ## End Stream ## \n",
    "    ## Start Data Storage ## \n",
    "    \n",
    "    # This pads/trims the data so it's 256 timesteps long (or whatever the sampling frequency is)\n",
    "    data = pad_or_trim(data, sampling_freq*duration) # -> (channels, sampling_freq) shape. Or (4, 256) for Muse2. [EEG only]\n",
    "\n",
    "    data = np.expand_dims(data, 0)\n",
    "    label = np.array([midi_note]) # Saves the current note as a feature.\n",
    "    if session_features is None:\n",
    "        session_features = data \n",
    "        session_labels = label\n",
    "    else:\n",
    "        session_features = np.append(session_features, data, axis=0)\n",
    "        session_labels = np.append(session_labels, label, axis=0)\n",
    "\n",
    "    \n",
    "    # This clears the Python notebook output.\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_features_denoised = session_features.copy()\n",
    "session_features_decomposed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would have to denoise the data.\n",
    "### TO IMPLEMENT: Data denoising.\n",
    "# Refer to this: https://brainflow.readthedocs.io/en/stable/Examples.html#python-denoising\n",
    "# Note: This function performs denoising IN PLACE.\n",
    "nfft = DataFilter.get_nearest_power_of_two(sampling_freq) # This is used to extract the band power.\n",
    "\n",
    "for idx in range(len(session_features_denoised)):\n",
    "    for channel in range(len(session_features_denoised[idx])):\n",
    "        # This part performs the denoising INPLACE.\n",
    "        DataFilter.perform_wavelet_denoising(session_features_denoised[idx][channel],\n",
    "                                     WaveletTypes.BIOR3_9,\n",
    "                                     3,\n",
    "                                     WaveletDenoisingTypes.SURESHRINK,\n",
    "                                     ThresholdTypes.HARD,\n",
    "                                     WaveletExtensionTypes.SYMMETRIC,\n",
    "                                     NoiseEstimationLevelTypes.FIRST_LEVEL\n",
    "                                     )\n",
    "        \n",
    "for idx in range(len(session_features_denoised)):\n",
    "    for channel in range(len(session_features_denoised[idx])):\n",
    "        # Next, we'd also have to extract the different wave states from each channel.\n",
    "        # Refer to this: https://brainflow.readthedocs.io/en/stable/Examples.html#python-band-power\n",
    "\n",
    "        psd = DataFilter.get_psd_welch(session_features_denoised[idx][channel], 128, 128 // 2, sampling_freq,\n",
    "                                WindowOperations.BLACKMAN_HARRIS)\n",
    "\n",
    "        band_power_delta =  DataFilter.get_band_power(psd, 0.5, 4.0)\n",
    "        band_power_theta =  DataFilter.get_band_power(psd, 4.1, 8.0)\n",
    "        band_power_alpha = DataFilter.get_band_power(psd, 8.1, 12.0)\n",
    "        band_power_beta = DataFilter.get_band_power(psd, 12.1, 30.0)\n",
    "        band_power_gamma = DataFilter.get_band_power(psd, 14.1, 30.0)\n",
    "\n",
    "        band_power = np.array([band_power_delta, band_power_theta, band_power_alpha, band_power_beta, band_power_gamma])\n",
    "        band_power = np.expand_dims(band_power, axis=0)\n",
    "\n",
    "        if session_features_decomposed is None:\n",
    "            session_features_decomposed = band_power\n",
    "        else:\n",
    "            session_features_decomposed = np.append(session_features_decomposed, band_power, axis=0)\n",
    "        \n",
    "\n",
    "\n",
    "# However, through this, we still have the same amount of features. Therefore, we have to extract relevant features\n",
    "# from each of the wave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as a .npy file\n",
    "if save:\n",
    "    np.save(f'{session_start} RAW.npy', session_features)\n",
    "    np.save(f'{session_start} DECOMPOSED.npy', session_features_decomposed)\n",
    "    np.save(f'{session_start} DENOISED.npy', session_features_denoised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGenBCIVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
